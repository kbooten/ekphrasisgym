{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting `(noun, adjective, number_of_noun)` and `(noun, transitive_verb, number_of_noun)` Tuples\n",
    "\n",
    "I'm extracting yet more information from Gutenberg data. The `transitive_verb` is lemmatized. `number_of_noun` is `1` (singular) or `2` (plural). From the sentence \"The small dog ate the purple leaves.\":\n",
    "\n",
    ">`[(\"small\",\"dog\",1),(\"purple\",\"leaves\",2)]`\n",
    "\n",
    "and \n",
    "\n",
    ">`[(\"dog\",\"eat\",1)]`\n",
    "\n",
    "***\n",
    "\n",
    "Todo\n",
    "\n",
    "* don't just get adjectives, also participles like \"cooked cabbage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The det\n",
      "wild amod\n",
      "dog nsubj\n",
      "was ROOT\n",
      "small acomp\n",
      "and cc\n",
      "cold conj\n",
      ". punct\n",
      "  \n",
      "The det\n",
      "dog nsubj\n",
      "ate ROOT\n",
      "the det\n",
      "house dobj\n",
      ". punct\n",
      "  \n",
      "The det\n",
      "dog nsubj\n",
      "slept ROOT\n",
      ". punct\n"
     ]
    }
   ],
   "source": [
    "for a in nlp(u\"The wild dog was small and cold.  The dog ate the house.  The dog slept.\"):\n",
    "    print(a,a.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in some randomly chosen Gutenberg texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gb_files = [f for f in os.listdir(\"/Users/kyle/Documents/downloading_gutenberg/data/\") if f.startswith('gb_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19507"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gb_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to extract relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp(\"The wifes of the man was here.\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting `(possessed,possessor)` tuples conservatively: trying to get relationships like \"the scales of the fish\" also gets \"ball of yarn.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('small', 'frogs', 2), ('only', 'ones', 2), ('blue', 'house', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_adj2nouns(tempspacy):\n",
    "    \"\"\"\n",
    "    returns [(adjective, noun, number of noun),...]\n",
    "    \"\"\"\n",
    "    nouns = [\"NN\",\"NNS\"]\n",
    "    adj_noun_tuples = []\n",
    "    for token in tempspacy:  ## for every token in the document\n",
    "        try: \n",
    "            if token.dep_==\"amod\":  ## try to see if it is an `amod`, an adjective\n",
    "                if token.pos_==\"ADJ\":\n",
    "                    if token.head.tag_ in nouns:  ## try to see if the head is a noun\n",
    "                        adj_noun_tuples.append((token.text.lower(),token.head.text.lower(),1 if token.head.tag_==\"NN\" else 2)) ## add the modifying word and the lemma \n",
    "        except:\n",
    "            pass\n",
    "    return adj_noun_tuples\n",
    "                                       \n",
    "extract_adj2nouns(nlp(\"Frogs and small frogs were not the only ones there, in the blue house of the blue house.  The smiling dog walked itself through the house.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('men', 'circle', 2), ('man', 'eat', 1), ('dog', 'eat', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_noun2verb(tempspacy):\n",
    "    \"\"\"\n",
    "    returns [(noun, transitive verb, number of noun),...]\n",
    "    \"\"\"\n",
    "    \n",
    "    nouns = [\"NN\",\"NNS\"]\n",
    "\n",
    "    noun2verbs = []\n",
    "    \n",
    "    for token in tempspacy:\n",
    "        try:\n",
    "            if ((token.tag_ in nouns) and (token.dep_==\"nsubj\")): ## find a noun subject\n",
    "                verb = token.head  ## make sure it's head is a verb\n",
    "                if verb.pos_ == \"VERB\":  ## ...\n",
    "                    verb_children_deps = [c.dep_ for c in verb.children] ## make sure one of its deps has a dobj dependency\n",
    "                    if \"dobj\" in verb_children_deps:\n",
    "                        obj = [c for c in verb.children if c.dep_==\"dobj\"][0] ## just get the last one\n",
    "                        noun2verbs.append((token.text.lower(),verb.lemma_,1 if token.tag_==\"NN\" else 2))# just noun and the verb lemma #obj.text.lower())) ## get the lemma, lemmatized verb, and nonlematized object\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return noun2verbs\n",
    "\n",
    "\n",
    "extract_noun2verb(nlp(u\"He swung through the fence.  The men circling the house. While running down the street, the man ate apples from a cart. The tree bore fruit and lemons. The dog who ran through the night ate chicken through the night.  The woods are on fire.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to loop through a bunch of Gutenberg texts that I've randomly downloaded with the Gutenberg python package.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gutenberg.cleanup import strip_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19507/19507 [18:47:14<00:00,  3.47s/it]   \n"
     ]
    }
   ],
   "source": [
    "adj2nouns_tuples_with_filenumber = []\n",
    "noun2verb_tuples_with_filenumber = []\n",
    "\n",
    "for fy in tqdm(gb_files):\n",
    "    with open(\"/Users/kyle/Documents/downloading_gutenberg/data/\"+fy,'r') as f:\n",
    "        tempdata = f.read()\n",
    "        filenumber = fy.lstrip(\"gb_\").rstrip(\".txt\")\n",
    "        if \"Language: English\" in tempdata[:1000]:  ## make sure english \n",
    "            tempdata = strip_headers(tempdata)\n",
    "            tempspacy = nlp(tempdata[:200000])### limit to first n chars\n",
    "            ## (king,kingdom)\n",
    "            try:\n",
    "                for pp in extract_adj2nouns(tempspacy):\n",
    "                    adj2nouns_tuples_with_filenumber.append((filenumber,pp))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                for pp in extract_noun2verb(tempspacy):\n",
    "                    noun2verb_tuples_with_filenumber.append((filenumber,pp))\n",
    "            except:\n",
    "                pass\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(possessor,possessed)` tuples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2068', ('main', 'road', 1)),\n",
       " ('2068', ('gray', 'drapery', 1)),\n",
       " ('2068', ('front', 'yards', 2)),\n",
       " ('2068', ('new', 'weathervane', 1)),\n",
       " ('2068', ('regular', 'church', 1)),\n",
       " ('2068', ('fine', 'residence', 1)),\n",
       " ('2068', ('opposite', 'gate', 1)),\n",
       " ('2068', ('front', 'gate', 1)),\n",
       " ('2068', ('other', 'side', 1)),\n",
       " ('2068', ('main', 'road', 1)),\n",
       " ('2068', ('little', 'story', 1)),\n",
       " ('2068', ('populous', 'center', 1)),\n",
       " ('2068', ('precarious', 'earnings', 2)),\n",
       " ('2068', ('large', 'establishment', 1)),\n",
       " ('2068', ('wet', 'blanket', 1)),\n",
       " ('2068', ('small', 'yard', 1)),\n",
       " ('2068', ('venerable', 'trees', 2)),\n",
       " ('2068', ('conservative', 'trees', 2)),\n",
       " ('2068', ('old', 'age', 1)),\n",
       " ('2068', ('dismantled', 'room', 1)),\n",
       " ('2068', ('faded', 'carpet', 1)),\n",
       " ('2068', ('outward', 'appearances', 2)),\n",
       " ('2068', ('large', 'portion', 1)),\n",
       " ('2068', ('wet', 'blanket', 1)),\n",
       " ('2068', ('more', 'sunshine', 1)),\n",
       " ('2068', ('plump', 'arms', 2)),\n",
       " ('2068', ('strong', 'arms', 2)),\n",
       " ('2068', ('tall', 'boy', 1)),\n",
       " ('2068', ('high', 'boy', 1)),\n",
       " ('2068', ('old', 'trunk', 1))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj2nouns_tuples_with_filenumber[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17127986\n"
     ]
    }
   ],
   "source": [
    "print(len(adj2nouns_tuples_with_filenumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2068', ('weathervane', 'present', 1)),\n",
       " ('2068', ('gate', 'stand', 1)),\n",
       " ('2068', ('ward', 'remove', 1)),\n",
       " ('2068', ('pair', 'discuss', 1)),\n",
       " ('2068', ('discussion', 'reach', 1)),\n",
       " ('2068', ('passengers', 'make', 2)),\n",
       " ('2068', ('kind', 'keep', 1)),\n",
       " ('2068', ('family', 'get', 1)),\n",
       " ('2068', ('companion', 'put', 1)),\n",
       " ('2068', ('month', 'work', 1)),\n",
       " ('2068', ('sewin', 'keep', 1)),\n",
       " ('2068', ('nobody', 'owe', 1)),\n",
       " ('2068', ('youngster', 'cherish', 1)),\n",
       " ('2068', ('draught', 'keep', 1)),\n",
       " ('2068', ('latter', 'leave', 1)),\n",
       " ('2068', ('body', 'need', 1)),\n",
       " ('2068', ('girl', 'take', 1)),\n",
       " ('2068', ('tide', 'reach', 1)),\n",
       " ('2068', ('use', 'advise', 1)),\n",
       " ('2068', ('everybody', 'know', 1)),\n",
       " ('2068', ('nobody', 'take', 1)),\n",
       " ('2068', ('possibility', 'enter', 1)),\n",
       " ('2068', ('refusal', 'enter', 1)),\n",
       " ('2068', ('knees', 'give', 2)),\n",
       " ('2068', ('nobody', 'lead', 1)),\n",
       " ('2068', ('nobody', 'put', 1)),\n",
       " ('2068', ('everybody', 'know', 1)),\n",
       " ('2068', ('folks', 'say', 2)),\n",
       " ('2068', ('thing', 'say', 1)),\n",
       " ('2068', ('lady', 'give', 1))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun2verb_tuples_with_filenumber[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2161512\n"
     ]
    }
   ],
   "source": [
    "print(len(noun2verb_tuples_with_filenumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj2nouns_tuples_with_filenumber_unique_per_file = list(set(adj2nouns_tuples_with_filenumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new', 'place', 1),\n",
       " ('only', 'problem', 1),\n",
       " ('large', 'parcels', 2),\n",
       " ('regular', 'manner', 1),\n",
       " ('secret', 'suffering', 1),\n",
       " ('happy', 'provision', 1),\n",
       " ('whitened', 'necks', 2),\n",
       " ('few', 'people', 2),\n",
       " ('calm', 'assurance', 1),\n",
       " ('faint', 'tinge', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj2nouns_tuples = [tup for filenumber,tup in adj2nouns_tuples_with_filenumber_unique_per_file]\n",
    "adj2nouns_tuples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607644237915655"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj2nouns_tuples)/len(adj2nouns_tuples_with_filenumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun2verb_tuples_with_filenumber_unique_per_file = list(set(noun2verb_tuples_with_filenumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('education', 'demand', 1),\n",
       " ('diagram', 'show', 1),\n",
       " ('story', 'stir', 1),\n",
       " ('lamb', 'follow', 1),\n",
       " ('limestones', 'bear', 2),\n",
       " ('failure', 'bring', 1),\n",
       " ('officer', 'take', 1),\n",
       " ('mind', 'give', 1),\n",
       " ('scenery', 'lose', 1),\n",
       " ('bridge', 'cross', 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun2verb_tuples = [tup for filenumber,tup in noun2verb_tuples_with_filenumber_unique_per_file]\n",
    "noun2verb_tuples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12248532898146927"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noun2verb_tuples)/len(adj2nouns_tuples_with_filenumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"adj2nouns_tuples.json\",\"w\") as f:\n",
    "    json.dump(adj2nouns_tuples,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"noun2verb_tuples.json\",\"w\") as f:\n",
    "    json.dump(noun2verb_tuples,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
